{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary libraries and dataset\n",
    "import pandas as pd\n",
    "sales_data = pd.read_csv(\"/Users/zone/Desktop/Week2/Day 5/IronKaggle/sales.csv\")\n",
    "\n",
    "# DATA CLEANING\n",
    "\n",
    "# Convert 'date' column to datetime\n",
    "sales_data['date'] = pd.to_datetime(sales_data['date'])\n",
    "\n",
    "# One-hot encoding of 'state_holiday'\n",
    "sales_data_encoded = pd.get_dummies(sales_data, columns=['state_holiday'], drop_first=True)\n",
    "\n",
    "# Drop 'Unnamed: 0' column\n",
    "sales_data_cleaned = sales_data_encoded.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "#FEATURE ENGINEERING\n",
    "\n",
    "# Extract additional features from the 'date' column\n",
    "sales_data_cleaned['year'] = sales_data_cleaned['date'].dt.year\n",
    "sales_data_cleaned['month'] = sales_data_cleaned['date'].dt.month\n",
    "sales_data_cleaned['day'] = sales_data_cleaned['date'].dt.day\n",
    "sales_data_cleaned['week_of_year'] = sales_data_cleaned['date'].dt.isocalendar().week\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 629897 entries, 0 to 640839\n",
      "Data columns (total 15 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   store_ID             629897 non-null  int64         \n",
      " 1   day_of_week          629897 non-null  int64         \n",
      " 2   date                 629897 non-null  datetime64[ns]\n",
      " 3   nb_customers_on_day  629897 non-null  int64         \n",
      " 4   open                 629897 non-null  int64         \n",
      " 5   promotion            629897 non-null  int64         \n",
      " 6   school_holiday       629897 non-null  int64         \n",
      " 7   sales                629897 non-null  int64         \n",
      " 8   state_holiday_a      629897 non-null  bool          \n",
      " 9   state_holiday_b      629897 non-null  bool          \n",
      " 10  state_holiday_c      629897 non-null  bool          \n",
      " 11  year                 629897 non-null  int32         \n",
      " 12  month                629897 non-null  int32         \n",
      " 13  day                  629897 non-null  int32         \n",
      " 14  week_of_year         629897 non-null  UInt32        \n",
      "dtypes: UInt32(1), bool(3), datetime64[ns](1), int32(3), int64(7)\n",
      "memory usage: 55.3 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "    store_ID  day_of_week       date  nb_customers_on_day  open  promotion  \\\n",
       " 0       366            4 2013-04-18                  517     1          0   \n",
       " 1       394            6 2015-04-11                  694     1          0   \n",
       " 2       807            4 2013-08-29                  970     1          1   \n",
       " 3       802            2 2013-05-28                  473     1          1   \n",
       " 4       726            4 2013-10-10                 1068     1          1   \n",
       " \n",
       "    school_holiday  sales  state_holiday_a  state_holiday_b  state_holiday_c  \\\n",
       " 0               0   4422            False            False            False   \n",
       " 1               0   8297            False            False            False   \n",
       " 2               0   9729            False            False            False   \n",
       " 3               0   6513            False            False            False   \n",
       " 4               0  10882            False            False            False   \n",
       " \n",
       "    year  month  day  week_of_year  \n",
       " 0  2013      4   18            16  \n",
       " 1  2015      4   11            15  \n",
       " 2  2013      8   29            35  \n",
       " 3  2013      5   28            22  \n",
       " 4  2013     10   10            41  )"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ADITIONAL PREPROCESSING STEPS\n",
    "\n",
    "# Check for outliers \n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Calculate the Z-score for 'sales' and 'nb_customers_on_day'\n",
    "sales_z_scores = stats.zscore(sales_data_cleaned['sales'])\n",
    "customers_z_scores = stats.zscore(sales_data_cleaned['nb_customers_on_day'])\n",
    "\n",
    "# Identify outliers (Z-score > 3 or Z-score < -3)\n",
    "outliers_sales = (abs(sales_z_scores) > 3)\n",
    "outliers_customers = (abs(customers_z_scores) > 3)\n",
    "\n",
    "# Remove the outliers from the dataset\n",
    "sales_data_no_z_outliers = sales_data_cleaned[~(outliers_sales | outliers_customers)]\n",
    "\n",
    "# Display the size of the dataset after removing outliers\n",
    "sales_data_no_z_outliers.info(), sales_data_no_z_outliers.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((503917, 13), (125980, 13), (503917,), (125980,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = sales_data_no_z_outliers.drop(columns=['sales', 'date'])\n",
    "y = sales_data_no_z_outliers['sales']\n",
    "\n",
    "# Perform an 80/20 train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the size of the training and testing sets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1673060.7451727511, 0.8649088693573258)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = linear_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "mse, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(695351.1767549412, 0.9438539354099544)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the Random Forest model on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "mse_rf, r2_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "9 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.89345787 0.89321512 0.89360022        nan        nan 0.89345494\n",
      " 0.89103365 0.89437256        nan 0.89349918]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30}\n",
      "MSE: 1305008.891728689, R²: 0.8946271812359279\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=42),\n",
    "                                   param_distributions=param_grid,\n",
    "                                   n_iter=10,  # Number of combinations to try\n",
    "                                   cv=3,       # 3-fold cross-validation\n",
    "                                   random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)  # This step is crucial\n",
    "\n",
    "# Retrieve the best hyperparameters and evaluate performance\n",
    "best_rf_model = random_search.best_estimator_  # Now this works after fitting\n",
    "y_pred_rf_tuned = best_rf_model.predict(X_test)\n",
    "\n",
    "# Calculate MSE and R²\n",
    "mse_rf_tuned = mean_squared_error(y_test, y_pred_rf_tuned)\n",
    "r2_rf_tuned = r2_score(y_test, y_pred_rf_tuned)\n",
    "\n",
    "# Display the best parameters and model performance\n",
    "print(\"Best Parameters: \", random_search.best_params_)\n",
    "print(f\"MSE: {mse_rf_tuned}, R²: {r2_rf_tuned}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'predicted_sales_real_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Load the real-life dataset \n",
    "real_life_data = pd.read_csv(\"/Users/zone/Desktop/Week2/Day 5/IronKaggle/REAL_DATA.csv\")\n",
    "\n",
    "# Preprocess the data (apply the same steps as the training set)\n",
    "real_life_data['date'] = pd.to_datetime(real_life_data['date'], dayfirst=True)\n",
    "real_life_data_encoded = pd.get_dummies(real_life_data, columns=['state_holiday'], drop_first=True)\n",
    "\n",
    "# Align the real-life dataset with the training dataset columns\n",
    "\n",
    "# Make sure the real-life dataset has the same columns as in the training set\n",
    "missing_cols = set(X_train.columns) - set(real_life_data_encoded.columns)\n",
    "for col in missing_cols:\n",
    "    real_life_data_encoded[col] = 0  # Add missing columns with default values\n",
    "\n",
    "# Ensure the order of columns is the same as in the training set\n",
    "real_life_data_encoded = real_life_data_encoded[X_train.columns]\n",
    "\n",
    "# Make predictions using the trained model\n",
    "predicted_sales = best_rf_model.predict(real_life_data_encoded)\n",
    "\n",
    "# Add predictions to the dataset and save to CSV\n",
    "real_life_data['sales'] = predicted_sales\n",
    "real_life_data.to_csv('predicted_sales_real_data.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to 'predicted_sales_real_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
